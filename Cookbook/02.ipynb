{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCLdJJWurIUYSJeAFhSlLF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grtlinux/KieaColab23/blob/main/Cookbook/02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python Cookbook\n",
        "\n",
        "02. "
      ],
      "metadata": {
        "id": "GHEN479kBGiJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbxAtjzD5ury"
      },
      "outputs": [],
      "source": [
        "# example.py\n",
        "#\n",
        "# Example of combining text via generators\n",
        "\n",
        "def sample():\n",
        "    yield \"Is\"\n",
        "    yield \"Chicago\"\n",
        "    yield \"Not\"\n",
        "    yield \"Chicago?\"\n",
        "\n",
        "# (a) Simple join operator\n",
        "text = ''.join(sample())\n",
        "print(text)\n",
        "\n",
        "# (b) Redirection of parts to I/O\n",
        "import sys\n",
        "for part in sample():\n",
        "    sys.stdout.write(part)\n",
        "sys.stdout.write('\\n')\n",
        "\n",
        "# (c) Combination of parts into buffers and larger I/O operations\n",
        "def combine(source, maxsize):\n",
        "    parts = []\n",
        "    size = 0\n",
        "    for part in source:\n",
        "        parts.append(part)\n",
        "        size += len(part)\n",
        "        if size > maxsize:\n",
        "            yield ''.join(parts)\n",
        "            parts = []\n",
        "            size = 0\n",
        "    yield ''.join(parts)\n",
        "\n",
        "for part in combine(sample(), 32768):\n",
        "    sys.stdout.write(part)\n",
        "sys.stdout.write('\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example.py\n",
        "#\n",
        "# Examples of simple regular expression matching\n",
        "\n",
        "import re\n",
        "\n",
        "# Some sample text\n",
        "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
        "\n",
        "# (a) Find all matching dates\n",
        "datepat = re.compile(r'\\d+/\\d+/\\d+')\n",
        "print(datepat.findall(text))\n",
        "\n",
        "# (b) Find all matching dates with capture groups\n",
        "datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n",
        "for month, day, year in datepat.findall(text):\n",
        "    print('{}-{}-{}'.format(year, month, day))\n",
        "\n",
        "# (c) Iterative search\n",
        "for m in datepat.finditer(text):\n",
        "    print(m.groups())\n",
        "\n"
      ],
      "metadata": {
        "id": "kes0QHvFBbF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example.py\n",
        "#\n",
        "# Example of using shell-wildcard style matching in list comprehensions\n",
        "\n",
        "from fnmatch import fnmatchcase as match\n",
        "\n",
        "addresses = [\n",
        "    '5412 N CLARK ST',\n",
        "    '1060 W ADDISON ST',\n",
        "    '1039 W GRANVILLE AVE',\n",
        "    '2122 N CLARK ST',\n",
        "    '4802 N BROADWAY',\n",
        "]\n",
        "\n",
        "a = [addr for addr in addresses if match(addr, '* ST')]\n",
        "print(a)\n",
        "\n",
        "b = [addr for addr in addresses if match(addr, '54[0-9][0-9] *CLARK*')]\n",
        "print(b)"
      ],
      "metadata": {
        "id": "alH-W6W3BbmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example.py\n",
        "#\n",
        "# Example of unicode normalization\n",
        "\n",
        "# Two strings\n",
        "s1 = 'Spicy Jalape\\u00f1o'\n",
        "s2 = 'Spicy Jalapen\\u0303o'\n",
        "\n",
        "# (a) Print them out (usually looks identical)\n",
        "print(s1)\n",
        "print(s2)\n",
        "\n",
        "# (b) Examine equality and length\n",
        "print('s1 == s2', s1 == s2)\n",
        "print(len(s1), len(s2))\n",
        "\n",
        "# (c) Normalize and try the same experiment\n",
        "import unicodedata\n",
        "\n",
        "n_s1 = unicodedata.normalize('NFC', s1)\n",
        "n_s2 = unicodedata.normalize('NFC', s2)\n",
        "\n",
        "print('n_s1 == n_s2', n_s1 == n_s2)\n",
        "print(len(n_s1), len(n_s2))\n",
        "\n",
        "# (d) Example of normalizing to a decomposed form and stripping accents\n",
        "t1 = unicodedata.normalize('NFD', s1)\n",
        "print(''.join(c for c in t1 if not unicodedata.combining(c)))"
      ],
      "metadata": {
        "id": "yZajujPlBb7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example.py\n",
        "#\n",
        "# Examples of reformatting text to different column widths\n",
        "\n",
        "# A long string\n",
        "s = \"Look into my eyes, look into my eyes, the eyes, the eyes, \\\n",
        "the eyes, not around the eyes, don't look around the eyes, \\\n",
        "look into my eyes, you're under.\"\n",
        "\n",
        "import textwrap\n",
        "\n",
        "print(textwrap.fill(s, 70))\n",
        "print()\n",
        "\n",
        "print(textwrap.fill(s, 40))\n",
        "print()\n",
        "\n",
        "print(textwrap.fill(s, 40, initial_indent='    '))\n",
        "print()\n",
        "\n",
        "print(textwrap.fill(s, 40, subsequent_indent='    '))\n",
        "print()\n"
      ],
      "metadata": {
        "id": "LJU66XnMBcMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example.py\n",
        "#\n",
        "# Example of some tricky sanitization problems\n",
        "\n",
        "# A tricky string\n",
        "s = 'p\\xfdt\\u0125\\xf6\\xf1\\x0cis\\tawesome\\r\\n'\n",
        "print(s)\n",
        "\n",
        "# (a) Remapping whitespace\n",
        "remap = {\n",
        "    ord('\\t') : ' ',\n",
        "    ord('\\f') : ' ',\n",
        "    ord('\\r') : None      # Deleted\n",
        "}\n",
        "\n",
        "a = s.translate(remap)\n",
        "print('whitespace remapped:', a)\n",
        "\n",
        "# (b) Remove all combining characters/marks\n",
        "import unicodedata\n",
        "import sys\n",
        "cmb_chrs = dict.fromkeys(c for c in range(sys.maxunicode)\n",
        "                         if unicodedata.combining(chr(c)))\n",
        "\n",
        "b = unicodedata.normalize('NFD', a)\n",
        "c = b.translate(cmb_chrs)\n",
        "print('accents removed:', c)\n",
        "\n",
        "# (c) Accent removal using I/O decoding\n",
        "d = b.encode('ascii','ignore').decode('ascii')\n",
        "print('accents removed via I/O:', d)\n"
      ],
      "metadata": {
        "id": "Z5gakmPoBcow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example.py\n",
        "#\n",
        "# Examples of simple regular expression substitution\n",
        "\n",
        "import re\n",
        "\n",
        "# Some sample text\n",
        "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
        "\n",
        "datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n",
        "\n",
        "# (a) Simple substitution\n",
        "print(datepat.sub(r'\\3-\\1-\\2', text))\n",
        "\n",
        "# (b) Replacement function\n",
        "from calendar import month_abbr\n",
        "\n",
        "def change_date(m):\n",
        "    mon_name = month_abbr[int(m.group(1))]\n",
        "    return '{} {} {}'.format(m.group(2), mon_name, m.group(3))\n",
        "\n",
        "print(datepat.sub(change_date, text))\n"
      ],
      "metadata": {
        "id": "XmMcpTCKBc2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example.py\n",
        "#\n",
        "# Example of a regular expression that finds shortest matches\n",
        "\n",
        "import re\n",
        "\n",
        "# Sample text\n",
        "text = 'Computer says \"no.\" Phone says \"yes.\"'\n",
        "\n",
        "# (a) Regex that finds quoted strings - longest match\n",
        "str_pat = re.compile(r'\\\"(.*)\\\"')\n",
        "print(str_pat.findall(text))\n",
        "\n",
        "# (b) Regex that finds quoted strings - shortest match\n",
        "str_pat = re.compile(r'\\\"(.*?)\\\"')\n",
        "print(str_pat.findall(text))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eHuK-gvKBdAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example.py\n",
        "#\n",
        "# Example of splitting a string on multiple delimiters using a regex\n",
        "\n",
        "import re\n",
        "\n",
        "line = 'asdf fjdk; afed, fjek,asdf,      foo'\n",
        "\n",
        "# (a) Splitting on space, comma, and semicolon\n",
        "parts = re.split(r'[;,\\s]\\s*', line)\n",
        "print(parts)\n",
        "\n",
        "# (b) Splitting with a capture group\n",
        "fields = re.split(r'(;|,|\\s)\\s*', line)\n",
        "print(fields)\n",
        "\n",
        "# (c) Rebuilding a string using fields above\n",
        "values = fields[::2]\n",
        "delimiters = fields[1::2]\n",
        "delimiters.append('')\n",
        "print('value =', values)\n",
        "print('delimiters =', delimiters)\n",
        "newline = ''.join(v+d for v,d in zip(values, delimiters))\n",
        "print('newline =', newline)\n",
        "\n",
        "# (d) Splitting using a non-capture group\n",
        "parts = re.split(r'(?:,|;|\\s)\\s*', line)\n",
        "print(parts)\n"
      ],
      "metadata": {
        "id": "5vhjG-ftBdLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example.py\n",
        "#\n",
        "# Example of a tokenizer\n",
        "\n",
        "import re\n",
        "from collections import namedtuple\n",
        "\n",
        "NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)'\n",
        "NUM  = r'(?P<NUM>\\d+)'\n",
        "PLUS = r'(?P<PLUS>\\+)'\n",
        "TIMES = r'(?P<TIMES>\\*)'\n",
        "EQ    = r'(?P<EQ>=)'\n",
        "WS    = r'(?P<WS>\\s+)'\n",
        "\n",
        "master_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS]))\n",
        "\n",
        "Token = namedtuple('Token', ['type','value'])\n",
        "\n",
        "def generate_tokens(pat, text):\n",
        "    scanner = pat.scanner(text)\n",
        "    for m in iter(scanner.match, None):\n",
        "        yield Token(m.lastgroup, m.group())\n",
        "\n",
        "for tok in generate_tokens(master_pat, 'foo = 42'):\n",
        "    print(tok)\n"
      ],
      "metadata": {
        "id": "tsU0iHHoBdV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example.py\n",
        "#\n",
        "# Examples of variable interpolation\n",
        "\n",
        "# Class for performing safe substitutions\n",
        "class safesub(dict):\n",
        "    def __missing__(self, key):\n",
        "        return '{%s}' % key\n",
        "\n",
        "s = '{name} has {n} messages.'\n",
        "\n",
        "# (a) Simple substitution\n",
        "name = 'Guido'\n",
        "n = 37\n",
        "\n",
        "print(s.format_map(vars()))\n",
        "\n",
        "# (b) Safe substitution with missing values\n",
        "del n\n",
        "print(s.format_map(safesub(vars())))\n",
        "\n",
        "# (c) Safe substitution + frame hack\n",
        "n = 37\n",
        "import sys\n",
        "def sub(text):\n",
        "    return text.format_map(safesub(sys._getframe(1).f_locals))\n",
        "\n",
        "print(sub('Hello {name}'))\n",
        "print(sub('{name} has {n} messages'))\n",
        "print(sub('Your favorite color is {color}'))\n"
      ],
      "metadata": {
        "id": "50Za5XuvBdfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example.py\n",
        "#\n",
        "# Regular expression that matches multiline patterns\n",
        "\n",
        "import re\n",
        "\n",
        "text = '''/* this is a\n",
        "              multiline comment */\n",
        "'''\n",
        "\n",
        "comment = re.compile(r'/\\*((?:.|\\n)*?)\\*/')\n",
        "print(comment.findall(text))\n"
      ],
      "metadata": {
        "id": "HW1fBX-HBdo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example.py\n",
        "#\n",
        "# An example of writing a simple recursive descent parser\n",
        "\n",
        "import re\n",
        "import collections\n",
        "\n",
        "# Token specification\n",
        "NUM    = r'(?P<NUM>\\d+)'\n",
        "PLUS   = r'(?P<PLUS>\\+)'\n",
        "MINUS  = r'(?P<MINUS>-)'\n",
        "TIMES  = r'(?P<TIMES>\\*)'\n",
        "DIVIDE = r'(?P<DIVIDE>/)'\n",
        "LPAREN = r'(?P<LPAREN>\\()'\n",
        "RPAREN = r'(?P<RPAREN>\\))'\n",
        "WS     = r'(?P<WS>\\s+)'\n",
        "\n",
        "master_pat = re.compile('|'.join([NUM, PLUS, MINUS, TIMES, \n",
        "                                  DIVIDE, LPAREN, RPAREN, WS]))\n",
        "\n",
        "# Tokenizer\n",
        "Token = collections.namedtuple('Token', ['type','value'])\n",
        "\n",
        "def generate_tokens(text):\n",
        "    scanner = master_pat.scanner(text)\n",
        "    for m in iter(scanner.match, None):\n",
        "        tok = Token(m.lastgroup, m.group())\n",
        "        if tok.type != 'WS':\n",
        "            yield tok\n",
        "\n",
        "# Parser \n",
        "class ExpressionEvaluator:\n",
        "    '''\n",
        "    Implementation of a recursive descent parser.   Each method\n",
        "    implements a single grammar rule.  Use the ._accept() method\n",
        "    to test and accept the current lookahead token.  Use the ._expect()\n",
        "    method to exactly match and discard the next token on on the input\n",
        "    (or raise a SyntaxError if it doesn't match).\n",
        "    '''\n",
        "\n",
        "    def parse(self,text):\n",
        "        self.tokens = generate_tokens(text)\n",
        "        self.tok = None             # Last symbol consumed\n",
        "        self.nexttok = None         # Next symbol tokenized\n",
        "        self._advance()             # Load first lookahead token\n",
        "        return self.expr()\n",
        "\n",
        "    def _advance(self):\n",
        "        'Advance one token ahead'\n",
        "        self.tok, self.nexttok = self.nexttok, next(self.tokens, None)\n",
        "\n",
        "    def _accept(self,toktype):\n",
        "        'Test and consume the next token if it matches toktype'\n",
        "        if self.nexttok and self.nexttok.type == toktype:\n",
        "            self._advance()\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def _expect(self,toktype):\n",
        "        'Consume next token if it matches toktype or raise SyntaxError'\n",
        "        if not self._accept(toktype):\n",
        "            raise SyntaxError('Expected ' + toktype)\n",
        "\n",
        "    # Grammar rules follow\n",
        "\n",
        "    def expr(self):\n",
        "        \"expression ::= term { ('+'|'-') term }*\"\n",
        "\n",
        "        exprval = self.term()\n",
        "        while self._accept('PLUS') or self._accept('MINUS'):\n",
        "            op = self.tok.type\n",
        "            right = self.term()\n",
        "            if op == 'PLUS':\n",
        "                exprval += right\n",
        "            elif op == 'MINUS':\n",
        "                exprval -= right\n",
        "        return exprval\n",
        "    \n",
        "    def term(self):\n",
        "        \"term ::= factor { ('*'|'/') factor }*\"\n",
        "\n",
        "        termval = self.factor()\n",
        "        while self._accept('TIMES') or self._accept('DIVIDE'):\n",
        "            op = self.tok.type\n",
        "            right = self.factor()\n",
        "            if op == 'TIMES':\n",
        "                termval *= right\n",
        "            elif op == 'DIVIDE':\n",
        "                termval /= right\n",
        "        return termval\n",
        "\n",
        "    def factor(self):\n",
        "        \"factor ::= NUM | ( expr )\"\n",
        "\n",
        "        if self._accept('NUM'):\n",
        "            return int(self.tok.value)\n",
        "        elif self._accept('LPAREN'):\n",
        "            exprval = self.expr()\n",
        "            self._expect('RPAREN')\n",
        "            return exprval\n",
        "        else:\n",
        "            raise SyntaxError('Expected NUMBER or LPAREN')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    e = ExpressionEvaluator()\n",
        "    print(e.parse('2'))\n",
        "    print(e.parse('2 + 3'))\n",
        "    print(e.parse('2 + 3 * 4'))\n",
        "    print(e.parse('2 + (3 + 4) * 5'))\n",
        "\n",
        "# Example of building trees\n",
        "\n",
        "class ExpressionTreeBuilder(ExpressionEvaluator):\n",
        "    def expr(self):\n",
        "        \"expression ::= term { ('+'|'-') term }\"\n",
        "\n",
        "        exprval = self.term()\n",
        "        while self._accept('PLUS') or self._accept('MINUS'):\n",
        "            op = self.tok.type\n",
        "            right = self.term()\n",
        "            if op == 'PLUS':\n",
        "                exprval = ('+', exprval, right)\n",
        "            elif op == 'MINUS':\n",
        "                exprval = ('-', exprval, right)\n",
        "        return exprval\n",
        "    \n",
        "    def term(self):\n",
        "        \"term ::= factor { ('*'|'/') factor }\"\n",
        "\n",
        "        termval = self.factor()\n",
        "        while self._accept('TIMES') or self._accept('DIVIDE'):\n",
        "            op = self.tok.type\n",
        "            right = self.factor()\n",
        "            if op == 'TIMES':\n",
        "                termval = ('*', termval, right)\n",
        "            elif op == 'DIVIDE':\n",
        "                termval = ('/', termval, right)\n",
        "        return termval\n",
        "\n",
        "    def factor(self):\n",
        "        'factor ::= NUM | ( expr )'\n",
        "\n",
        "        if self._accept('NUM'):\n",
        "            return int(self.tok.value)\n",
        "        elif self._accept('LPAREN'):\n",
        "            exprval = self.expr()\n",
        "            self._expect('RPAREN')\n",
        "            return exprval\n",
        "        else:\n",
        "            raise SyntaxError('Expected NUMBER or LPAREN')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    e = ExpressionTreeBuilder()\n",
        "    print(e.parse('2 + 3'))\n",
        "    print(e.parse('2 + 3 * 4'))\n",
        "    print(e.parse('2 + (3 + 4) * 5'))\n",
        "    print(e.parse('2 + 3 + 4'))\n",
        "    "
      ],
      "metadata": {
        "id": "pu5MtnQbBeJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plyexample.py\n",
        "#\n",
        "# Example of parsing with PLY\n",
        "\n",
        "from ply.lex import lex\n",
        "from ply.yacc import yacc\n",
        "\n",
        "# Token list\n",
        "tokens = [ 'NUM', 'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'LPAREN', 'RPAREN' ]\n",
        "\n",
        "# Ignored characters\n",
        "\n",
        "t_ignore = ' \\t\\n'\n",
        "\n",
        "# Token specifications (as regexs)\n",
        "t_PLUS   = r'\\+'\n",
        "t_MINUS  = r'-'\n",
        "t_TIMES  = r'\\*'\n",
        "t_DIVIDE = r'/'\n",
        "t_LPAREN = r'\\('\n",
        "t_RPAREN = r'\\)'\n",
        "\n",
        "# Token processing functions\n",
        "def t_NUM(t):\n",
        "    r'\\d+'\n",
        "    t.value = int(t.value)\n",
        "    return t\n",
        "\n",
        "# Error handler\n",
        "def t_error(t):\n",
        "    print('Bad character: {!r}'.format(t.value[0]))\n",
        "    t.skip(1)\n",
        "\n",
        "# Build the lexer\n",
        "lexer = lex()\n",
        "\n",
        "# Grammar rules and handler functions\n",
        "def p_expr(p):\n",
        "    '''\n",
        "    expr : expr PLUS term\n",
        "         | expr MINUS term\n",
        "    '''\n",
        "    if p[2] == '+':\n",
        "        p[0] = p[1] + p[3]\n",
        "    elif p[2] == '-':\n",
        "        p[0] = p[1] - p[3]\n",
        "\n",
        "def p_expr_term(p):\n",
        "    '''\n",
        "    expr : term\n",
        "    '''\n",
        "    p[0] = p[1]\n",
        "\n",
        "def p_term(p):\n",
        "    '''\n",
        "    term : term TIMES factor\n",
        "         | term DIVIDE factor\n",
        "    '''\n",
        "    if p[2] == '*':\n",
        "        p[0] = p[1] * p[3]\n",
        "    elif p[2] == '/':\n",
        "        p[0] = p[1] / p[3]\n",
        "\n",
        "def p_term_factor(p):\n",
        "    '''\n",
        "    term : factor\n",
        "    '''\n",
        "    p[0] = p[1]\n",
        "\n",
        "def p_factor(p):\n",
        "    '''\n",
        "    factor : NUM\n",
        "    '''\n",
        "    p[0] = p[1]\n",
        "\n",
        "def p_factor_group(p):\n",
        "    '''\n",
        "    factor : LPAREN expr RPAREN\n",
        "    '''\n",
        "    p[0] = p[2]\n",
        "\n",
        "def p_error(p):\n",
        "    print('Syntax error')\n",
        "\n",
        "parser = yacc()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(parser.parse('2'))\n",
        "    print(parser.parse('2+3'))\n",
        "    print(parser.parse('2+(3+4)*5'))\n",
        "    "
      ],
      "metadata": {
        "id": "fFEX86znBeUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c67TrY2BBee5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eSuQ-SWzBeot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uywJveTaBfCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i-p0WKBHBfL3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}